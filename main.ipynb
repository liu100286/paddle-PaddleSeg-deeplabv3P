{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压一下略小改之后的PaddleSeg，解压一次就可以注释掉了\r\n",
    "!unzip -oq /home/aistudio/PaddleSeg.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压数据集\r\n",
    "!unzip -qo data/data100087/B榜测试数据集.zip -d data/\r\n",
    "# !unzip -oq data/data95249/第一阶段test.zip -d data/\r\n",
    "!unzip -qo data/data95249/train_50k_mask.zip -d data/\r\n",
    "!unzip -oq data/data95249/train_image.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import sys\r\n",
    "sys.path.append(\"PaddleSeg\")\r\n",
    "import paddleseg\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "from tqdm import tqdm\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "#设置随机数种子\r\n",
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "#数据增强 ,垂直翻转,水平翻转\r\n",
    "def imageFlip(image1,path,name):\r\n",
    "    # 图像左右翻转，上下翻转\r\n",
    "    name=name.split(\".\")[0]\r\n",
    "    # path=\"testimg\"\r\n",
    "    flip_horizontal = cv2.flip(image1, 1)\r\n",
    "    cv2.imwrite(os.path.join(path,name+\"1\" +\".png\"),flip_horizontal)\r\n",
    "    # cv2.imshow(\"flip_horizontal\",flip_horizontal)\r\n",
    "    flip_vertical = cv2.flip(image1, 0)\r\n",
    "    cv2.imwrite(os.path.join(path,name+\"2\" +\".png\"),flip_vertical)\r\n",
    "    flip_hv = cv2.flip(image1, -1)\r\n",
    "    cv2.imwrite(os.path.join(path,name+\"3\" +\".png\"),flip_hv)\r\n",
    "    \r\n",
    "def EnhanceData():\r\n",
    "    path1=\"data/train_image\"\r\n",
    "    path2=\"data/train_50k_mask\"\r\n",
    "    imagePathlist=os.listdir(path1)\r\n",
    "    for dirName in imagePathlist:\r\n",
    "        print(dirName)\r\n",
    "        filenamepath1=os.path.join(path1,dirName)\r\n",
    "        filenamepath2=os.path.join(path2,dirName)\r\n",
    "        imagenames=os.listdir(filenamepath2)\r\n",
    "        \r\n",
    "        for imagename in imagenames:\r\n",
    "            # print(filenamepath1,imagename)\r\n",
    "            # print(filenamepath2,imagename)\r\n",
    "            img1=cv2.imread(os.path.join(filenamepath1,imagename))\r\n",
    "            img2=cv2.imread(os.path.join(filenamepath2,imagename))\r\n",
    "            imageFlip(img1,filenamepath1,imagename)\r\n",
    "            imageFlip(img2,filenamepath2,imagename)\r\n",
    "        #     break\r\n",
    "        # break\r\n",
    "\r\n",
    "# 如需扩展数据请打开下面的注释\r\n",
    "# EnhanceData()\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_txt(file_name, imgs_path, labels_path=None, mode='train', val_pro=0.2):\r\n",
    "    assert mode==\"train\" or mode==\"test\", \"ERROR:mode must be train or test.\"\r\n",
    "    if mode!=\"test\":\r\n",
    "        train_path = []\r\n",
    "        for idx, f_path in enumerate(imgs_path):\r\n",
    "            for i_path in sorted(os.listdir(f_path)):\r\n",
    "                path1 = os.path.join(f_path, i_path) \r\n",
    "                path2 = os.path.join(labels_path[idx], i_path)\r\n",
    "                train_path.append((path1, path2, str(idx)))\r\n",
    "        \r\n",
    "        if val_pro>=0 and val_pro<=1:\r\n",
    "            #打乱数据\r\n",
    "            random.shuffle(train_path)\r\n",
    "            val_len = int(len(train_path)*val_pro)\r\n",
    "            val_path = train_path[:val_len]\r\n",
    "            train_path = train_path[val_len:]\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")\r\n",
    "            with open(file_name[1], 'w') as f:\r\n",
    "                for path in val_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\")  \r\n",
    "            return len(train_path), val_len\r\n",
    "        else:\r\n",
    "            with open(file_name[0], 'w') as f:\r\n",
    "                for path in train_path:\r\n",
    "                    f.write(path[0]+\" \"+path[1]+\" \"+path[2]+\"\\n\") \r\n",
    "            return len(train_path), 0\r\n",
    "    else:\r\n",
    "        with open(file_name, 'w') as f:\r\n",
    "            for path in imgs_path:\r\n",
    "                img_path = os.path.join(test_path, path)\r\n",
    "                f.write(img_path+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_txt(data_root, train_imgs_dir=None, train_labels_dir=None, test_dir=None, val_pro=0.2):\r\n",
    "    if train_imgs_dir is not None:\r\n",
    "        if os.path.exists(\"train.txt\"):\r\n",
    "            os.remove(\"train.txt\")\r\n",
    "        if os.path.exists(\"val.txt\"):\r\n",
    "            os.remove(\"val.txt\")\r\n",
    "        train_imgs_dir = os.path.join(data_root, train_imgs_dir)\r\n",
    "        train_labels_dir = os.path.join(data_root, train_labels_dir)\r\n",
    "        file_names = os.listdir(train_imgs_dir)\r\n",
    "        file_names = sorted(file_names)\r\n",
    "        train_imgs_path, train_labels_path =[], []\r\n",
    "        for na in file_names:\r\n",
    "            train_imgs_path.append(os.path.join(train_imgs_dir, na))\r\n",
    "            train_labels_path.append(os.path.join(train_labels_dir, na))\r\n",
    "        train_len, val_len = write_txt([\"train.txt\", \"val.txt\"], train_imgs_path, train_labels_path, mode='train', val_pro=val_pro)\r\n",
    "        \r\n",
    "        print(\"训练数据整理完毕！训练集长度：{}，验证集长度：{}， 类别数：{}\".format(train_len, val_len, len(file_names)))\r\n",
    "\r\n",
    "    if test_dir is not None:\r\n",
    "        if os.path.exists(\"test.txt\"):\r\n",
    "            os.remove(\"test.txt\")\r\n",
    "        global test_path\r\n",
    "        test_path = os.path.join(data_root, test_dir)\r\n",
    "        test_imgs_path_list = sorted(os.listdir(test_path))\r\n",
    "        write_txt(\"test.txt\", test_imgs_path_list, mode=\"test\")\r\n",
    "        print(\"测试数据整理完毕！测试集长度：{}\".format(len(test_imgs_path_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据整理完毕！训练集长度：49500，验证集长度：500， 类别数：500\n",
      "测试数据整理完毕！测试集长度：10989\n"
     ]
    }
   ],
   "source": [
    "data_root = \"data\"\r\n",
    "train_imgs_dir = \"train_image\"\r\n",
    "train_labels_dir = \"train_50k_mask\"\r\n",
    "# test_dir = \"val_image\"\r\n",
    "test_dir = \"test_image\"\r\n",
    "create_txt(data_root, train_imgs_dir, train_labels_dir, test_dir, val_pro=0.01) # val_pro 设置 1% 的数据为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 参数配置及训练\n",
    "#MyDeeplabv3p.yml中可以修改参数配置，请自行体验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-04 17:34:52 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-150-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "cudnn: 7.6\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: Tesla V100-SXM2-32GB']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.1.0\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2021-08-04 17:34:52 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "AUG:\n",
      "  AUG_METHOD: unpadding\n",
      "  FIX_RESIZE_SIZE: (512, 512)\n",
      "  FLIP: true\n",
      "  FLIP_RATIO: 0.5\n",
      "  MIRROR: true\n",
      "  MIRROR_RATIO: 0.5\n",
      "  RichCrop:\n",
      "    BLUR: true\n",
      "    BLUR_RATIO: 0.2\n",
      "    BRIGHTNESS_JITTER_RATIO: 0.7\n",
      "    CONTRAST_JITTER_RATIO: 0.7\n",
      "    ENABLE: true\n",
      "    MIN_AREA_RATIO: 0.9\n",
      "    SATURATION_JITTER_RATIO: 0.7\n",
      "batch_size: 32\n",
      "iters: 30000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - coef:\n",
      "    - 1.0\n",
      "    losses:\n",
      "    - type: CrossEntropyLoss\n",
      "    type: MixedLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  align_corners: false\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet101_vd_ssld.tar.gz\n",
      "    type: ResNet101_vd\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 3\n",
      "  num_classes: 2\n",
      "  pretrained: null\n",
      "  type: DeepLabV3P\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: /home/aistudio/train.txt\n",
      "  transforms:\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/val.txt\n",
      "------------------------------------------------\n",
      "W0804 17:34:53.086216   359 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0804 17:34:53.086277   359 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "2021-08-04 17:34:58 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet101_vd_ssld.tar.gz\n",
      "Connecting to https://bj.bcebos.com/paddleseg/dygraph/resnet101_vd_ssld.tar.gz\n",
      "Downloading resnet101_vd_ssld.tar.gz\n",
      "[==================================================] 100.00%\n",
      "Uncompress resnet101_vd_ssld.tar.gz\n",
      "[==================================================] 100.00%\n",
      "2021-08-04 17:35:08 [INFO]\tThere are 530/530 variables loaded into ResNet_vd.\n",
      "2021-08-04 17:35:09 [INFO]\tResume model from /home/aistudio/output_deeplabv3_1/iter_4000\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n",
      "2021-08-04 17:41:42 [INFO]\t[TRAIN] epoch: 3, iter: 4200/30000, loss: 0.1221, lr: 0.008731, batch_cost: 1.9467, reader_cost: 0.00519, ips: 16.4384 samples/sec | ETA 13:57:03\n",
      "2021-08-04 17:48:11 [INFO]\t[TRAIN] epoch: 3, iter: 4400/30000, loss: 0.1308, lr: 0.008670, batch_cost: 1.9464, reader_cost: 0.00021, ips: 16.4403 samples/sec | ETA 13:50:28\n",
      "2021-08-04 17:54:40 [INFO]\t[TRAIN] epoch: 3, iter: 4600/30000, loss: 0.1270, lr: 0.008609, batch_cost: 1.9464, reader_cost: 0.00021, ips: 16.4407 samples/sec | ETA 13:43:58\n",
      "2021-08-04 18:01:10 [INFO]\t[TRAIN] epoch: 4, iter: 4800/30000, loss: 0.1206, lr: 0.008548, batch_cost: 1.9473, reader_cost: 0.00038, ips: 16.4328 samples/sec | ETA 13:37:52\n",
      "2021-08-04 18:07:39 [INFO]\t[TRAIN] epoch: 4, iter: 5000/30000, loss: 0.1243, lr: 0.008487, batch_cost: 1.9471, reader_cost: 0.00019, ips: 16.4345 samples/sec | ETA 13:31:18\n",
      "2021-08-04 18:14:09 [INFO]\t[TRAIN] epoch: 4, iter: 5200/30000, loss: 0.1265, lr: 0.008426, batch_cost: 1.9473, reader_cost: 0.00024, ips: 16.4330 samples/sec | ETA 13:24:53\n",
      "2021-08-04 18:20:38 [INFO]\t[TRAIN] epoch: 4, iter: 5400/30000, loss: 0.1261, lr: 0.008365, batch_cost: 1.9473, reader_cost: 0.00021, ips: 16.4329 samples/sec | ETA 13:18:23\n",
      "2021-08-04 18:27:09 [INFO]\t[TRAIN] epoch: 4, iter: 5600/30000, loss: 0.1229, lr: 0.008303, batch_cost: 1.9523, reader_cost: 0.00535, ips: 16.3912 samples/sec | ETA 13:13:55\n",
      "2021-08-04 18:33:38 [INFO]\t[TRAIN] epoch: 4, iter: 5800/30000, loss: 0.1162, lr: 0.008242, batch_cost: 1.9472, reader_cost: 0.00021, ips: 16.4337 samples/sec | ETA 13:05:22\n",
      "2021-08-04 18:40:07 [INFO]\t[TRAIN] epoch: 4, iter: 6000/30000, loss: 0.1126, lr: 0.008181, batch_cost: 1.9473, reader_cost: 0.00021, ips: 16.4332 samples/sec | ETA 12:58:54\n",
      "2021-08-04 18:40:07 [INFO]\tStart evaluating (total_samples: 500, total_iters: 500)...\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int32, but right dtype is paddle.bool, the right dtype will convert to paddle.int32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:239: UserWarning: The dtype of left and right variables are not the same, left dtype is paddle.int64, but right dtype is paddle.bool, the right dtype will convert to paddle.int64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "500/500 [==============================] - 35s 70ms/step - batch_cost: 0.0701 - reader cost: 1.4394e-\n",
      "2021-08-04 18:40:43 [INFO]\t[EVAL] #Images: 500 mIoU: 0.8567 Acc: 0.9354 Kappa: 0.8437 \n",
      "2021-08-04 18:40:43 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9128 0.8005]\n",
      "2021-08-04 18:40:43 [INFO]\t[EVAL] Class Acc: \n",
      "[0.9704 0.855 ]\n",
      "2021-08-04 18:40:48 [INFO]\t[EVAL] The model with the best validation mIoU (0.8567) was saved at iter 6000.\n",
      "2021-08-04 18:47:17 [INFO]\t[TRAIN] epoch: 5, iter: 6200/30000, loss: 0.1142, lr: 0.008119, batch_cost: 1.9450, reader_cost: 0.00021, ips: 16.4523 samples/sec | ETA 12:51:31\n",
      "2021-08-04 18:53:47 [INFO]\t[TRAIN] epoch: 5, iter: 6400/30000, loss: 0.1123, lr: 0.008058, batch_cost: 1.9479, reader_cost: 0.00024, ips: 16.4281 samples/sec | ETA 12:46:09\n",
      "2021-08-04 19:00:16 [INFO]\t[TRAIN] epoch: 5, iter: 6600/30000, loss: 0.1143, lr: 0.007997, batch_cost: 1.9475, reader_cost: 0.00024, ips: 16.4314 samples/sec | ETA 12:39:31\n",
      "2021-08-04 19:06:46 [INFO]\t[TRAIN] epoch: 5, iter: 6800/30000, loss: 0.1185, lr: 0.007935, batch_cost: 1.9478, reader_cost: 0.00021, ips: 16.4290 samples/sec | ETA 12:33:08\n",
      "2021-08-04 19:13:15 [INFO]\t[TRAIN] epoch: 5, iter: 7000/30000, loss: 0.1144, lr: 0.007873, batch_cost: 1.9478, reader_cost: 0.00021, ips: 16.4288 samples/sec | ETA 12:26:39\n",
      "2021-08-04 19:19:46 [INFO]\t[TRAIN] epoch: 5, iter: 7200/30000, loss: 0.1094, lr: 0.007812, batch_cost: 1.9527, reader_cost: 0.00444, ips: 16.3872 samples/sec | ETA 12:22:02\n",
      "2021-08-04 19:26:15 [INFO]\t[TRAIN] epoch: 5, iter: 7400/30000, loss: 0.0967, lr: 0.007750, batch_cost: 1.9476, reader_cost: 0.00020, ips: 16.4308 samples/sec | ETA 12:13:34\n",
      "2021-08-04 19:32:45 [INFO]\t[TRAIN] epoch: 5, iter: 7600/30000, loss: 0.1031, lr: 0.007688, batch_cost: 1.9475, reader_cost: 0.00023, ips: 16.4309 samples/sec | ETA 12:07:05\n",
      "2021-08-04 19:39:14 [INFO]\t[TRAIN] epoch: 6, iter: 7800/30000, loss: 0.0999, lr: 0.007627, batch_cost: 1.9473, reader_cost: 0.00021, ips: 16.4326 samples/sec | ETA 12:00:31\n",
      "2021-08-04 19:45:44 [INFO]\t[TRAIN] epoch: 6, iter: 8000/30000, loss: 0.1008, lr: 0.007565, batch_cost: 1.9472, reader_cost: 0.00021, ips: 16.4338 samples/sec | ETA 11:53:58\n",
      "2021-08-04 19:45:44 [INFO]\tStart evaluating (total_samples: 500, total_iters: 500)...\n",
      "500/500 [==============================] - 31s 62ms/step - batch_cost: 0.0615 - reader cost: 1.4308e-\n",
      "2021-08-04 19:46:15 [INFO]\t[EVAL] #Images: 500 mIoU: 0.8601 Acc: 0.9383 Kappa: 0.8475 \n",
      "2021-08-04 19:46:15 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9176 0.8026]\n",
      "2021-08-04 19:46:15 [INFO]\t[EVAL] Class Acc: \n",
      "[0.9598 0.8839]\n",
      "2021-08-04 19:46:20 [INFO]\t[EVAL] The model with the best validation mIoU (0.8601) was saved at iter 8000.\n",
      "2021-08-04 19:52:49 [INFO]\t[TRAIN] epoch: 6, iter: 8200/30000, loss: 0.1104, lr: 0.007503, batch_cost: 1.9458, reader_cost: 0.00029, ips: 16.4456 samples/sec | ETA 11:46:58\n",
      "2021-08-04 19:59:19 [INFO]\t[TRAIN] epoch: 6, iter: 8400/30000, loss: 0.1134, lr: 0.007441, batch_cost: 1.9472, reader_cost: 0.00022, ips: 16.4337 samples/sec | ETA 11:40:59\n",
      "2021-08-04 20:05:48 [INFO]\t[TRAIN] epoch: 6, iter: 8600/30000, loss: 0.1235, lr: 0.007379, batch_cost: 1.9484, reader_cost: 0.00021, ips: 16.4236 samples/sec | ETA 11:34:56\n",
      "2021-08-04 20:12:19 [INFO]\t[TRAIN] epoch: 6, iter: 8800/30000, loss: 0.1014, lr: 0.007317, batch_cost: 1.9540, reader_cost: 0.00487, ips: 16.3767 samples/sec | ETA 11:30:24\n",
      "2021-08-04 20:18:49 [INFO]\t[TRAIN] epoch: 6, iter: 9000/30000, loss: 0.1030, lr: 0.007254, batch_cost: 1.9479, reader_cost: 0.00022, ips: 16.4280 samples/sec | ETA 11:21:45\n",
      "2021-08-04 20:25:18 [INFO]\t[TRAIN] epoch: 6, iter: 9200/30000, loss: 0.0999, lr: 0.007192, batch_cost: 1.9472, reader_cost: 0.00023, ips: 16.4340 samples/sec | ETA 11:15:01\n",
      "2021-08-04 20:31:48 [INFO]\t[TRAIN] epoch: 7, iter: 9400/30000, loss: 0.0992, lr: 0.007130, batch_cost: 1.9472, reader_cost: 0.00023, ips: 16.4338 samples/sec | ETA 11:08:32\n",
      "2021-08-04 20:38:17 [INFO]\t[TRAIN] epoch: 7, iter: 9600/30000, loss: 0.1026, lr: 0.007068, batch_cost: 1.9471, reader_cost: 0.00021, ips: 16.4346 samples/sec | ETA 11:02:00\n",
      "2021-08-04 20:44:47 [INFO]\t[TRAIN] epoch: 7, iter: 9800/30000, loss: 0.1003, lr: 0.007005, batch_cost: 1.9470, reader_cost: 0.00022, ips: 16.4353 samples/sec | ETA 10:55:29\n",
      "2021-08-04 20:51:16 [INFO]\t[TRAIN] epoch: 7, iter: 10000/30000, loss: 0.1025, lr: 0.006943, batch_cost: 1.9470, reader_cost: 0.00021, ips: 16.4353 samples/sec | ETA 10:49:00\n",
      "2021-08-04 20:51:16 [INFO]\tStart evaluating (total_samples: 500, total_iters: 500)...\n",
      "500/500 [==============================] - 33s 66ms/step - batch_cost: 0.0660 - reader cost: 1.4385e-\n",
      "2021-08-04 20:51:49 [INFO]\t[EVAL] #Images: 500 mIoU: 0.8588 Acc: 0.9372 Kappa: 0.8461 \n",
      "2021-08-04 20:51:49 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9158 0.8018]\n",
      "2021-08-04 20:51:49 [INFO]\t[EVAL] Class Acc: \n",
      "[0.9637 0.8726]\n",
      "2021-08-04 20:51:53 [INFO]\t[EVAL] The model with the best validation mIoU (0.8601) was saved at iter 8000.\n",
      "2021-08-04 20:58:23 [INFO]\t[TRAIN] epoch: 7, iter: 10200/30000, loss: 0.0977, lr: 0.006880, batch_cost: 1.9488, reader_cost: 0.00357, ips: 16.4206 samples/sec | ETA 10:43:05\n",
      "2021-08-04 21:04:52 [INFO]\t[TRAIN] epoch: 7, iter: 10400/30000, loss: 0.0904, lr: 0.006818, batch_cost: 1.9477, reader_cost: 0.00024, ips: 16.4299 samples/sec | ETA 10:36:14\n",
      "2021-08-04 21:11:22 [INFO]\t[TRAIN] epoch: 7, iter: 10600/30000, loss: 0.0890, lr: 0.006755, batch_cost: 1.9478, reader_cost: 0.00027, ips: 16.4284 samples/sec | ETA 10:29:48\n",
      "2021-08-04 21:17:51 [INFO]\t[TRAIN] epoch: 7, iter: 10800/30000, loss: 0.0889, lr: 0.006692, batch_cost: 1.9471, reader_cost: 0.00021, ips: 16.4343 samples/sec | ETA 10:23:05\n",
      "2021-08-04 21:24:21 [INFO]\t[TRAIN] epoch: 8, iter: 11000/30000, loss: 0.0877, lr: 0.006630, batch_cost: 1.9484, reader_cost: 0.00022, ips: 16.4239 samples/sec | ETA 10:16:59\n",
      "2021-08-04 21:30:50 [INFO]\t[TRAIN] epoch: 8, iter: 11200/30000, loss: 0.0898, lr: 0.006567, batch_cost: 1.9483, reader_cost: 0.00022, ips: 16.4242 samples/sec | ETA 10:10:28\n",
      "2021-08-04 21:37:20 [INFO]\t[TRAIN] epoch: 8, iter: 11400/30000, loss: 0.0904, lr: 0.006504, batch_cost: 1.9471, reader_cost: 0.00024, ips: 16.4349 samples/sec | ETA 10:03:35\n",
      "2021-08-04 21:43:49 [INFO]\t[TRAIN] epoch: 8, iter: 11600/30000, loss: 0.0905, lr: 0.006441, batch_cost: 1.9468, reader_cost: 0.00022, ips: 16.4375 samples/sec | ETA 09:57:00\n",
      "2021-08-04 21:50:20 [INFO]\t[TRAIN] epoch: 8, iter: 11800/30000, loss: 0.0894, lr: 0.006378, batch_cost: 1.9521, reader_cost: 0.00480, ips: 16.3925 samples/sec | ETA 09:52:08\n",
      "2021-08-04 21:56:49 [INFO]\t[TRAIN] epoch: 8, iter: 12000/30000, loss: 0.0800, lr: 0.006315, batch_cost: 1.9468, reader_cost: 0.00024, ips: 16.4371 samples/sec | ETA 09:44:02\n",
      "2021-08-04 21:56:49 [INFO]\tStart evaluating (total_samples: 500, total_iters: 500)...\n",
      "500/500 [==============================] - 32s 63ms/step - batch_cost: 0.0631 - reader cost: 1.4548e-0\n",
      "2021-08-04 21:57:21 [INFO]\t[EVAL] #Images: 500 mIoU: 0.8641 Acc: 0.9399 Kappa: 0.8523 \n",
      "2021-08-04 21:57:21 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9194 0.8087]\n",
      "2021-08-04 21:57:21 [INFO]\t[EVAL] Class Acc: \n",
      "[0.9639 0.8807]\n",
      "2021-08-04 21:57:26 [INFO]\t[EVAL] The model with the best validation mIoU (0.8641) was saved at iter 12000.\n",
      "2021-08-04 22:03:55 [INFO]\t[TRAIN] epoch: 8, iter: 12200/30000, loss: 0.0845, lr: 0.006252, batch_cost: 1.9452, reader_cost: 0.00020, ips: 16.4511 samples/sec | ETA 09:37:03\n",
      "2021-08-04 22:10:24 [INFO]\t[TRAIN] epoch: 9, iter: 12400/30000, loss: 0.0813, lr: 0.006188, batch_cost: 1.9461, reader_cost: 0.00024, ips: 16.4431 samples/sec | ETA 09:30:51\n",
      "2021-08-04 22:16:54 [INFO]\t[TRAIN] epoch: 9, iter: 12600/30000, loss: 0.0828, lr: 0.006125, batch_cost: 1.9473, reader_cost: 0.00023, ips: 16.4329 samples/sec | ETA 09:24:43\n",
      "2021-08-04 22:23:23 [INFO]\t[TRAIN] epoch: 9, iter: 12800/30000, loss: 0.0839, lr: 0.006062, batch_cost: 1.9465, reader_cost: 0.00022, ips: 16.4397 samples/sec | ETA 09:17:59\n",
      "2021-08-04 22:29:52 [INFO]\t[TRAIN] epoch: 9, iter: 13000/30000, loss: 0.0842, lr: 0.005998, batch_cost: 1.9461, reader_cost: 0.00022, ips: 16.4433 samples/sec | ETA 09:11:23\n",
      "2021-08-04 22:36:22 [INFO]\t[TRAIN] epoch: 9, iter: 13200/30000, loss: 0.0838, lr: 0.005935, batch_cost: 1.9465, reader_cost: 0.00022, ips: 16.4400 samples/sec | ETA 09:05:00\n",
      "2021-08-04 22:42:52 [INFO]\t[TRAIN] epoch: 9, iter: 13400/30000, loss: 0.0790, lr: 0.005871, batch_cost: 1.9492, reader_cost: 0.00398, ips: 16.4173 samples/sec | ETA 08:59:16\n",
      "2021-08-04 22:49:21 [INFO]\t[TRAIN] epoch: 9, iter: 13600/30000, loss: 0.0763, lr: 0.005807, batch_cost: 1.9457, reader_cost: 0.00024, ips: 16.4469 samples/sec | ETA 08:51:48\n",
      "2021-08-04 22:55:50 [INFO]\t[TRAIN] epoch: 9, iter: 13800/30000, loss: 0.0783, lr: 0.005744, batch_cost: 1.9456, reader_cost: 0.00021, ips: 16.4472 samples/sec | ETA 08:45:19\n",
      "2021-08-04 23:02:19 [INFO]\t[TRAIN] epoch: 10, iter: 14000/30000, loss: 0.0761, lr: 0.005680, batch_cost: 1.9469, reader_cost: 0.00025, ips: 16.4364 samples/sec | ETA 08:39:10\n",
      "2021-08-04 23:02:19 [INFO]\tStart evaluating (total_samples: 500, total_iters: 500)...\n",
      "500/500 [==============================] - 31s 61ms/step - batch_cost: 0.0610 - reader cost: 1.3868e-0\n",
      "2021-08-04 23:02:50 [INFO]\t[EVAL] #Images: 500 mIoU: 0.8714 Acc: 0.9436 Kappa: 0.8609 \n",
      "2021-08-04 23:02:50 [INFO]\t[EVAL] Class IoU: \n",
      "[0.9244 0.8184]\n",
      "2021-08-04 23:02:50 [INFO]\t[EVAL] Class Acc: \n",
      "[0.9639 0.8927]\n",
      "2021-08-04 23:02:55 [INFO]\t[EVAL] The model with the best validation mIoU (0.8714) was saved at iter 14000.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !python PaddleSeg/train.py --config my_deeplabv3.yml --do_eval --use_vdl --save_dir /home/aistudio/output_deeplabv3_1 --save_interval 2000\r\n",
    "# !python PaddleSeg/train.py --config my_deeplabv3.yml --do_eval --use_vdl --save_dir /home/aistudio/output_deeplabv3_1 --save_interval 2000 --resume_model /home/aistudio/output_deeplabv3_1/iter_20000\r\n",
    "#  --resume_model 恢复模型路径,首次训练请移除此参数\r\n",
    "#  \r\n",
    "#  \r\n",
    "!python PaddleSeg/train.py --config MyDeeplabv3p.yml --do_eval --use_vdl --save_dir /home/aistudio/output_deeplabv3_1 --save_interval 2000 --resume_model /home/aistudio/output_deeplabv3_1/iter_4000\r\n",
    "\r\n",
    "# \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 推理\n",
    "已在PaddleSeg中做了修改可以直接预测出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-04 23:05:41 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "AUG:\n",
      "  AUG_METHOD: unpadding\n",
      "  FIX_RESIZE_SIZE: (512, 512)\n",
      "  FLIP: true\n",
      "  FLIP_RATIO: 0.5\n",
      "  MIRROR: true\n",
      "  MIRROR_RATIO: 0.5\n",
      "  RichCrop:\n",
      "    BLUR: true\n",
      "    BLUR_RATIO: 0.2\n",
      "    BRIGHTNESS_JITTER_RATIO: 0.7\n",
      "    CONTRAST_JITTER_RATIO: 0.7\n",
      "    ENABLE: true\n",
      "    MIN_AREA_RATIO: 0.9\n",
      "    SATURATION_JITTER_RATIO: 0.7\n",
      "batch_size: 32\n",
      "iters: 30000\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - coef:\n",
      "    - 1.0\n",
      "    losses:\n",
      "    - type: CrossEntropyLoss\n",
      "    type: MixedLoss\n",
      "lr_scheduler:\n",
      "  end_lr: 0\n",
      "  learning_rate: 0.01\n",
      "  power: 0.9\n",
      "  type: PolynomialDecay\n",
      "model:\n",
      "  align_corners: false\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet101_vd_ssld.tar.gz\n",
      "    type: ResNet101_vd\n",
      "  backbone_indices:\n",
      "  - 0\n",
      "  - 3\n",
      "  num_classes: 2\n",
      "  pretrained: null\n",
      "  type: DeepLabV3P\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: train\n",
      "  num_classes: 2\n",
      "  train_path: /home/aistudio/train.txt\n",
      "  transforms:\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: RandomVerticalFlip\n",
      "  - brightness_range: 0.4\n",
      "    contrast_range: 0.4\n",
      "    saturation_range: 0.4\n",
      "    type: RandomDistort\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio\n",
      "  mode: val\n",
      "  num_classes: 2\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/val.txt\n",
      "------------------------------------------------\n",
      "W0804 23:05:41.435200 12991 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0804 23:05:41.435251 12991 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "2021-08-04 23:05:46 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet101_vd_ssld.tar.gz\n",
      "2021-08-04 23:05:48 [INFO]\tThere are 530/530 variables loaded into ResNet_vd.\n",
      "2021-08-04 23:05:48 [INFO]\tNumber of predict images = 10989\n",
      "2021-08-04 23:05:48 [INFO]\tLoading pretrained model from output_deeplabv3_1/iter_14000/model.pdparams\n",
      "2021-08-04 23:05:50 [INFO]\tThere are 615/615 variables loaded into DeepLabV3P.\n",
      "2021-08-04 23:05:50 [INFO]\tStart to predict...\n",
      "10989/10989 [==============================] - 915s 83ms/ste\n"
     ]
    }
   ],
   "source": [
    "#推理output_deeplabv3_1/iter_30000\r\n",
    "# !python PaddleSeg/predict.py --config my_deeplabv3.yml --model_path output_deeplabv3_1/iter_28000/model.pdparams --image_path data/test_image --save_dir output/result_1 #--aug_pred --flip_horizontal --flip_vertical\r\n",
    "\r\n",
    "!python PaddleSeg/predict.py --config MyDeeplabv3p.yml --model_path output_deeplabv3_1/iter_14000/model.pdparams --image_path data/test_image --save_dir output/result_1 #--aug_pred --flip_horizontal --flip_vertical\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 压缩结果，提交文件\n",
    "[第三届中国AI+创新创业大赛：半监督学习目标定位竞赛](https://aistudio.baidu.com/aistudio/competition/detail/78)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/output/result_1/results\n",
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "%cd output/result_1/results\r\n",
    "!zip -r -oq /home/aistudio/pred.zip ./\r\n",
    "%cd /home/aistudio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
